{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3-p1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scotthou94/applied_deep_learning/blob/master/hw3_p1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-bunb_qEJ5lU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hw3-P1\n",
        "The dataset used in this part is created based on the loader notebook provided by instructor. Each class has 1k images and we have 10 classes in total. The dataset is saved to my google drive and made public. "
      ]
    },
    {
      "metadata": {
        "id": "0Ru7h75XLaug",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import functools, itertools, json, os, re, textwrap\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "tfe = tf.contrib.eager\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "from six.moves.urllib import request\n",
        "from xml.dom import minidom"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4G9NiEO5Knrx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the dataset from google drive\n",
        "\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '1SSIO4PbdlvpyTYMxvBn0phY8ba3DgLRX'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "# Save to local file\n",
        "target_path = 'quickdraw.npz'\n",
        "downloaded.GetContentFile(target_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R0r7_Qs1LFEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fae7df65-f2cf-445f-8d21-df2139d55a1e"
      },
      "cell_type": "code",
      "source": [
        "# Inspect the data\n",
        "with open(target_path, 'r') as f:\n",
        "  loaded = np.load(f)\n",
        "  X, y = loaded['X'], loaded['y']\n",
        "# Reshape the data so it has 1 color channel\n",
        "num = X.shape[0]\n",
        "a = X.shape[1]\n",
        "X = X.reshape((num, a, a, 1))\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 64, 64, 1) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3mpv7n8mLWq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4cfb04e-5f32-413a-c539-303bf5a62dd0"
      },
      "cell_type": "code",
      "source": [
        "# See the data scale\n",
        "print(X[0].shape, y[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 64, 1) zebra\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hsVuL6QcO46a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Steps\n",
        "1. Data preparation\n",
        "1. Split into train/validation/test\n",
        "1. Build model\n",
        "1. Compile\n",
        "1. Train\n",
        "1. Evaluate on test set"
      ]
    },
    {
      "metadata": {
        "id": "9bVFAJAcRIVd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data normalization\n",
        "X = X.astype('float32') / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r68YgZGUgrG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "459a2068-6ff4-4bbf-872d-3e00680b1804"
      },
      "cell_type": "code",
      "source": [
        "# Turn the y label to numeric format\n",
        "zoo = ['elephant', 'giraffe', 'kangaroo', 'lion', 'monkey', 'panda',\n",
        "       'penguin', 'rhinoceros', 'tiger', 'zebra']\n",
        "num = range(10)\n",
        "mapping = {}\n",
        "for animal, d in zip(zoo, num):\n",
        "  mapping[animal] = d\n",
        "  print(animal, d)\n",
        "for i in range(len(y)):\n",
        "  y[i] = mapping[y[i]]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "elephant 0\n",
            "giraffe 1\n",
            "kangaroo 2\n",
            "lion 3\n",
            "monkey 4\n",
            "panda 5\n",
            "penguin 6\n",
            "rhinoceros 7\n",
            "tiger 8\n",
            "zebra 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GR77N1orOjAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "21fbf0a4-94cf-44d7-979b-e6f39445bd20"
      },
      "cell_type": "code",
      "source": [
        "# Split into train/validation/test\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, shuffle=True)\n",
        "\n",
        "# Convert label to one-hot encoding\n",
        "num_classes = 10\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print(\"Train size\", x_train.shape, y_train.shape)\n",
        "print(\"Validation size\", x_val.shape, y_val.shape)\n",
        "print(\"Test size\", x_test.shape, y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size (6750, 64, 64, 1) (6750, 10)\n",
            "Validation size (2250, 64, 64, 1) (2250, 10)\n",
            "Test size (1000, 64, 64, 1) (1000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DY8W15-y6rYM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Experiment setup\n",
        "1. Compare batch size: 256, 32. Model 2 and 4\n",
        "1. Compare learning rate: 0.01/0.001/0.0001. Model 1 - 3\n",
        "1. Change filter size: (25, 25), (5, 5). Model 4 and 5"
      ]
    },
    {
      "metadata": {
        "id": "0U56oKyclzN5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model 1\n",
        "1. Learning rate 0.01\n",
        "1. Batch size 256\n",
        "1. filter size (5, 5)"
      ]
    },
    {
      "metadata": {
        "id": "mAMac9ClSHM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "dba60bbd-38fe-492e-e172-a87020fd01a4"
      },
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(64,64,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "# Take a look at the model summary\n",
        "model.summary()\n",
        "\n",
        "# Compile model\n",
        "adam1 = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=adam1,\n",
        "             metrics=['accuracy'])\n",
        "# Train model\n",
        "batch_size = 256\n",
        "epochs = 10\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 21, 21, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 424,362\n",
            "Trainable params: 424,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 86s 3s/step - loss: 2.2512 - acc: 0.1658 - val_loss: 1.8549 - val_acc: 0.3600\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 84s 3s/step - loss: 1.7859 - acc: 0.3730 - val_loss: 1.2725 - val_acc: 0.5782\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 84s 3s/step - loss: 1.4194 - acc: 0.5119 - val_loss: 1.0857 - val_acc: 0.6333\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 1.2163 - acc: 0.5748 - val_loss: 0.9029 - val_acc: 0.6938\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 84s 3s/step - loss: 1.0739 - acc: 0.6205 - val_loss: 0.8630 - val_acc: 0.7058\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 83s 3s/step - loss: 1.0158 - acc: 0.6434 - val_loss: 0.8069 - val_acc: 0.7311\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 0.9572 - acc: 0.6650 - val_loss: 0.7943 - val_acc: 0.7293\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 84s 3s/step - loss: 0.9380 - acc: 0.6726 - val_loss: 0.7909 - val_acc: 0.7471\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 84s 3s/step - loss: 0.9010 - acc: 0.6854 - val_loss: 0.7509 - val_acc: 0.7458\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 84s 3s/step - loss: 0.8862 - acc: 0.6882 - val_loss: 0.7382 - val_acc: 0.7489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0a8f34810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "_Xro6mn-mB7r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model 2\n",
        "1. Learning rates of 0.001\n",
        "1. Batch size 256\n",
        "1. Filter size (5, 5)"
      ]
    },
    {
      "metadata": {
        "id": "o09lfd49ZA-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "7a9a910e-412b-4a26-d876-b92771881756"
      },
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model2 = tf.keras.Sequential()\n",
        "\n",
        "model2.add(tf.keras.layers.Conv2D(64, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(64,64,1))) \n",
        "model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model2.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model2.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model2.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model2.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model2.add(tf.keras.layers.Flatten())\n",
        "model2.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model2.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "# Take a look at the model summary\n",
        "model2.summary()\n",
        "\n",
        "# Compile model\n",
        "lr = 0.001\n",
        "AdamOptimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "             optimizer=AdamOptimizer,\n",
        "             metrics=['accuracy'])\n",
        "# Train model\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                               min_delta=0.01,\n",
        "                                               patience=0,\n",
        "                                               verbose=1)\n",
        "batch_size = 256\n",
        "epochs = 10\n",
        "model2.fit(x_train,\n",
        "           y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           validation_data=(x_val, y_val))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 21, 21, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 424,362\n",
            "Trainable params: 424,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 86s 3s/step - loss: 1.9001 - acc: 0.3166 - val_loss: 1.3720 - val_acc: 0.5867\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 1.2779 - acc: 0.5502 - val_loss: 1.0058 - val_acc: 0.6844\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 1.0305 - acc: 0.6495 - val_loss: 0.8431 - val_acc: 0.7267\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 0.8861 - acc: 0.6945 - val_loss: 0.7673 - val_acc: 0.7436\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 86s 3s/step - loss: 0.8302 - acc: 0.7114 - val_loss: 0.7226 - val_acc: 0.7596\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 0.7643 - acc: 0.7330 - val_loss: 0.6645 - val_acc: 0.7796\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 0.7191 - acc: 0.7485 - val_loss: 0.6388 - val_acc: 0.7822\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 86s 3s/step - loss: 0.6798 - acc: 0.7610 - val_loss: 0.6390 - val_acc: 0.7862\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 84s 3s/step - loss: 0.6344 - acc: 0.7724 - val_loss: 0.5950 - val_acc: 0.7960\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 84s 3s/step - loss: 0.6055 - acc: 0.7855 - val_loss: 0.5777 - val_acc: 0.8013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0a6e73a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "zID4nwn3n9eK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model3\n",
        "1. Adam optimizer,  learning rate 0.0001\n",
        "1. Batch size 256\n",
        "1. Filter size (5, 5)"
      ]
    },
    {
      "metadata": {
        "id": "rTsdrJiInI1l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "41a52313-0553-44c7-932d-ea78aac46361"
      },
      "cell_type": "code",
      "source": [
        "# Model3\n",
        "model3 = tf.keras.Sequential()\n",
        "\n",
        "model3.add(tf.keras.layers.Conv2D(64, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(64,64,1))) \n",
        "model3.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model3.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model3.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model3.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model3.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model3.add(tf.keras.layers.Flatten())\n",
        "model3.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model3.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "# Take a look at the model summary\n",
        "model3.summary()\n",
        "\n",
        "# Compile model\n",
        "Adam = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "               optimizer=Adam,\n",
        "               metrics=['accuracy'])\n",
        "# Train model\n",
        "batch_size = 256\n",
        "epochs = 10\n",
        "model3.fit(x_train,\n",
        "           y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           validation_data=(x_val, y_val))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 64, 64, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 21, 21, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 424,362\n",
            "Trainable params: 424,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "27/27 [==============================] - 86s 3s/step - loss: 2.3028 - acc: 0.1235 - val_loss: 2.2407 - val_acc: 0.2111\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 2.1795 - acc: 0.2104 - val_loss: 2.1072 - val_acc: 0.4129\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 2.0000 - acc: 0.3027 - val_loss: 1.8356 - val_acc: 0.4902\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 84s 3s/step - loss: 1.8052 - acc: 0.3631 - val_loss: 1.5863 - val_acc: 0.5422\n",
            "Epoch 5/10\n",
            "27/27 [==============================] - 86s 3s/step - loss: 1.6688 - acc: 0.4155 - val_loss: 1.4605 - val_acc: 0.5791\n",
            "Epoch 6/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 1.5776 - acc: 0.4438 - val_loss: 1.3712 - val_acc: 0.5929\n",
            "Epoch 7/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 1.5047 - acc: 0.4728 - val_loss: 1.3108 - val_acc: 0.6120\n",
            "Epoch 8/10\n",
            "27/27 [==============================] - 86s 3s/step - loss: 1.4419 - acc: 0.4991 - val_loss: 1.2466 - val_acc: 0.6258\n",
            "Epoch 9/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 1.3913 - acc: 0.5108 - val_loss: 1.2028 - val_acc: 0.6462\n",
            "Epoch 10/10\n",
            "27/27 [==============================] - 85s 3s/step - loss: 1.3416 - acc: 0.5232 - val_loss: 1.1597 - val_acc: 0.6587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0a6b8f590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "ehD1K4ukxdl6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model4\n",
        "1. 0.001 learning rate\n",
        "1. 32 batch size\n",
        "1. 5 * 5 filter size"
      ]
    },
    {
      "metadata": {
        "id": "RQhyHAFjpYsB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "dcf4d867-3e0d-4322-a293-919ad8bd9494"
      },
      "cell_type": "code",
      "source": [
        "# Model4\n",
        "model4 = tf.keras.Sequential()\n",
        "\n",
        "model4.add(tf.keras.layers.Conv2D(64, kernel_size=(5, 5), padding='same', activation='relu', input_shape=(64,64,1))) \n",
        "model4.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model4.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model4.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model4.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model4.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model4.add(tf.keras.layers.Flatten())\n",
        "model4.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model4.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model4.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "# Take a look at the model summary\n",
        "model4.summary()\n",
        "\n",
        "# Compile model\n",
        "Adam4 = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "model4.compile(loss='categorical_crossentropy',\n",
        "               optimizer=Adam4,\n",
        "               metrics=['accuracy'])\n",
        "# Train model\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "model4.fit(x_train,\n",
        "           y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           validation_data=(x_val, y_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 21, 21, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 424,362\n",
            "Trainable params: 424,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 10s 45ms/step - loss: 1.4987 - acc: 0.4664 - val_loss: 0.8721 - val_acc: 0.7102\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 9s 44ms/step - loss: 0.9022 - acc: 0.6908 - val_loss: 0.7295 - val_acc: 0.7542\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 9s 44ms/step - loss: 0.7555 - acc: 0.7329 - val_loss: 0.6580 - val_acc: 0.7747\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 9s 44ms/step - loss: 0.6825 - acc: 0.7562 - val_loss: 0.6413 - val_acc: 0.7769\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 9s 44ms/step - loss: 0.6138 - acc: 0.7848 - val_loss: 0.6178 - val_acc: 0.7862\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 9s 44ms/step - loss: 0.5580 - acc: 0.8014 - val_loss: 0.6114 - val_acc: 0.7849\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 10s 46ms/step - loss: 0.5095 - acc: 0.8172 - val_loss: 0.5922 - val_acc: 0.7978\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 10s 47ms/step - loss: 0.4591 - acc: 0.8363 - val_loss: 0.5895 - val_acc: 0.7947\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 9s 44ms/step - loss: 0.4402 - acc: 0.8419 - val_loss: 0.5659 - val_acc: 0.8018\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 9s 44ms/step - loss: 0.4118 - acc: 0.8464 - val_loss: 0.5913 - val_acc: 0.7996\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f73337ccd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "WmBrybWn-FsT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model 5\n",
        "1. 25 \\* 25 and 20 \\* 20 filter size\n",
        "1. 0.001 learning rate\n",
        "1. Batch size 32"
      ]
    },
    {
      "metadata": {
        "id": "wx1TMzah-BlX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "75187117-9186-48b3-abff-c5dd5955ed34"
      },
      "cell_type": "code",
      "source": [
        "# Model5\n",
        "model5 = tf.keras.Sequential()\n",
        "\n",
        "model5.add(tf.keras.layers.Conv2D(64, kernel_size=(25, 25), padding='same', activation='relu', input_shape=(64,64,1))) \n",
        "model5.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model5.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model5.add(tf.keras.layers.Conv2D(32, kernel_size=(20, 20), padding='same', activation='relu'))\n",
        "model5.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "model5.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model5.add(tf.keras.layers.Flatten())\n",
        "model5.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model5.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "model5.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "# Take a look at the model summary\n",
        "model5.summary()\n",
        "\n",
        "# Compile model\n",
        "Adam5 = tf.train.AdamOptimizer(learning_rate=0.001)\n",
        "model5.compile(loss='categorical_crossentropy',\n",
        "               optimizer=Adam5,\n",
        "               metrics=['accuracy'])\n",
        "# Train model\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "model5.fit(x_train,\n",
        "           y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           validation_data=(x_val, y_val))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 64, 64, 64)        40064     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 21, 21, 32)        819232    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 1,263,530\n",
            "Trainable params: 1,263,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "211/211 [==============================] - 19s 91ms/step - loss: 1.5364 - acc: 0.4565 - val_loss: 0.9615 - val_acc: 0.6591\n",
            "Epoch 2/10\n",
            "211/211 [==============================] - 15s 71ms/step - loss: 0.9503 - acc: 0.6651 - val_loss: 0.8622 - val_acc: 0.6996\n",
            "Epoch 3/10\n",
            "211/211 [==============================] - 15s 71ms/step - loss: 0.7760 - acc: 0.7295 - val_loss: 0.7742 - val_acc: 0.7333\n",
            "Epoch 4/10\n",
            "211/211 [==============================] - 15s 71ms/step - loss: 0.6530 - acc: 0.7676 - val_loss: 0.7568 - val_acc: 0.7333\n",
            "Epoch 5/10\n",
            "211/211 [==============================] - 15s 71ms/step - loss: 0.5645 - acc: 0.8022 - val_loss: 0.6974 - val_acc: 0.7591\n",
            "Epoch 6/10\n",
            "211/211 [==============================] - 16s 74ms/step - loss: 0.4950 - acc: 0.8266 - val_loss: 0.7038 - val_acc: 0.7622\n",
            "Epoch 7/10\n",
            "211/211 [==============================] - 15s 72ms/step - loss: 0.4169 - acc: 0.8479 - val_loss: 0.7015 - val_acc: 0.7684\n",
            "Epoch 8/10\n",
            "211/211 [==============================] - 15s 71ms/step - loss: 0.3763 - acc: 0.8651 - val_loss: 0.6960 - val_acc: 0.7782\n",
            "Epoch 9/10\n",
            "211/211 [==============================] - 15s 71ms/step - loss: 0.3235 - acc: 0.8834 - val_loss: 0.7505 - val_acc: 0.7662\n",
            "Epoch 10/10\n",
            "211/211 [==============================] - 15s 71ms/step - loss: 0.2887 - acc: 0.8920 - val_loss: 0.7423 - val_acc: 0.7724\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f733374ea90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "W6Gp4bxWRUYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cbfe208e-6232-45c4-8613-a2127f2d820d"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate model 4\n",
        "test_loss, test_acc = model4.evaluate(x_test, y_test)\n",
        "print('test loss is {0}, test accuracy is {1}'.format(test_loss, test_acc))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 15ms/step\n",
            "test loss is 0.509465979576, test accuracy is 0.812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bgCtoDQa1_zy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "1. By comparing model 1 - 3, the best learning rate is 0.001\n",
        "1. By comparing model 2 and 4, the smaller batch size gives better validation accuracy but not by much\n",
        "1. By changing the filter size, model 5 gives worse performance than model 4 but still not by much.\n",
        "1. Here I evaluate the model 4, it gives a test accuracy of 0.812\n",
        "1. I think there's still room for improvement using fine-tuning but given the purpose of this assignment I think this is a reasonable accuracy."
      ]
    },
    {
      "metadata": {
        "id": "USsR9gsux0Jc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}